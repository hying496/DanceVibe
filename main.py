# Import necessary libraries
import sys
import os
import cv2
import numpy as np
import threading
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
from PIL import Image, ImageTk
import mediapipe as mp
import importlib.util
sys.path.append(os.path.join(os.path.dirname(__file__), 'detector'))
from detector.pose_detector import DetectorType, PoseDetectionManager
from detector.smoother import smooth_keypoints
from detector.fixer import fix_keypoints
from detector.tracker import Tracker
# å¯¼å…¥ç›¸ä¼¼åº¦è®¡ç®—
import numpy as np
from score.similarity import calculate_pose_similarity, center_landmarks, normalize_landmarks
from score.music_beat import mp4_2_mp3, get_beats
from score.motion_match import match_motion_to_beats
from score.score_pose import score_pose
from score.average_similarity import CumulativeScore
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

# Suppress MediaPipe warnings
import logging

import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['SimHei']  # æˆ– 'Microsoft YaHei'ï¼Œéœ€æœ¬åœ°æœ‰è¯¥å­—ä½“
matplotlib.rcParams['axes.unicode_minus'] = False

logging.getLogger('mediapipe').setLevel(logging.ERROR)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# æ ‡å‡†éª¨æ¶è¿æ¥ï¼ˆMediaPipe 33ç‚¹ï¼‰
MEDIAPIPE_CONNECTIONS = [
    (0,1),(1,2),(2,3),(3,7),(0,4),(4,5),(5,6),(6,8),
    (9,10),(11,12),(11,13),(13,15),(15,17),(15,19),(15,21),
    (17,19),(12,14),(14,16),(16,18),(16,20),(16,22),(18,20),
    (11,23),(12,24),(23,24),(23,25),(24,26),(25,27),(27,29),
    (29,31),(26,28),(28,30),(30,32)
]
# YOLOv8/COCO 17ç‚¹éª¨æ¶è¿æ¥
YOLOV8_CONNECTIONS = [
    (0,1),(0,2),(1,3),(2,4),(0,5),(0,6),(5,7),(7,9),(6,8),(8,10),
    (5,6),(5,11),(6,12),(11,12),(11,13),(13,15),(12,14),(14,16)
]

# ä¼˜åŒ–åçš„å¯è§†åŒ–å‡½æ•°
def draw_persons(frame, persons, detector_type):
    color_list = [(0,255,0), (255,0,0), (0,0,255), (255,255,0), (0,255,255), (255,0,255)]
    # é€‰æ‹©éª¨æ¶è¿æ¥
    if detector_type.value == 'mediapipe':
        connections = MEDIAPIPE_CONNECTIONS
    else:
        connections = YOLOV8_CONNECTIONS
    for idx, p in enumerate(persons):
        color = color_list[idx % len(color_list)]
        # ç”»éª¨æ¶
        for pt1, pt2 in connections:
            if pt1 < len(p.keypoints) and pt2 < len(p.keypoints):
                kp1, kp2 = p.keypoints[pt1], p.keypoints[pt2]
                if kp1.visible and kp2.visible:
                    cv2.line(frame, (int(kp1.x), int(kp1.y)), (int(kp2.x), int(kp2.y)), color, 2)
        # ç”»å…³é”®ç‚¹
        for kp in p.keypoints:
            if kp.visible:
                cv2.circle(frame, (int(kp.x), int(kp.y)), 4, color, -1)
        # ç”»æ‰‹éƒ¨
        for hand in getattr(p, 'hands', []):
            for kp in hand.keypoints:
                cv2.circle(frame, (int(kp.x), int(kp.y)), 2, (255,0,255), -1)
        # æ˜¾ç¤ºID
        if hasattr(p, 'id'):
            bbox = p.bbox
            cv2.putText(frame, f'ID:{p.id}', (int(bbox[0]), int(bbox[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
    return frame

def calc_similarity(lm1, lm2):
    return calculate_pose_similarity(lm1, lm2)

def center_landmarks_safe(landmarks):
    return center_landmarks(landmarks)
def normalize_landmarks_safe(landmarks_np):
    return normalize_landmarks(landmarks_np)

class MediaPipePoseApp:
    def __init__(self, root,
                 detector_type=DetectorType.MEDIAPIPE,
                 smoother_method=None,
                 fixer_method=None,
                 tracker_enable=False):
        self.root = root
        self.root.title("MediaPipe Dance GUI")
        # è‡ªåŠ¨æœ€å¤§åŒ–çª—å£
        try:
            self.root.state('zoomed')  # Windows
        except:
            try:
                self.root.attributes('-zoomed', True)  # Linux/Mac
            except:
                pass
        self.root.configure(bg='lightgray')

        # å‚æ•°
        self.detector_type = detector_type
        self.smoother_method = smoother_method  # 'ema'/'kalman'/None
        self.fixer_method = fixer_method        # 'linear'/'symmetric'/None
        self.tracker_enable = tracker_enable

        # åˆ†åˆ«ä¸ºå·¦/å³æµç»´æŠ¤ç‹¬ç«‹å¯¹è±¡
        self.file_pose_manager = PoseDetectionManager(detector_type)
        self.file_tracker = Tracker() if tracker_enable else None
        self.cam_pose_manager = PoseDetectionManager(detector_type)
        self.cam_tracker = Tracker() if tracker_enable else None

        self.running_file = False
        self.running_cam = False
        self.video_path = ""
        self.cap_file = None
        self.cap_cam = None
        self.show_video_frame = True

        self.similarity_calculator = SimilarityCalculator()
        self.last_file_landmarks = None  # è®°å½•å‚è€ƒè§†é¢‘ä¸»èˆè€…landmarks
        self.last_cam_landmarks = None   # è®°å½•webcamä¸»èˆè€…landmarks
        self.last_similarity = None

        self.beat_times = []
        self.cumulative_score = CumulativeScore()
        self.score_history = []
        self.fig, self.ax = plt.subplots(figsize=(4,1.2), dpi=100)
        self.score_canvas = None

        self.setup_gui()

    def setup_gui(self):
        # Main container
        main_frame = tk.Frame(self.root, bg='lightgray')
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # Left frame for reference video
        self.left_frame = tk.Frame(main_frame, bg='white', relief=tk.RAISED, bd=2)
        self.left_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(0, 5))

        # Right frame for webcam
        self.right_frame = tk.Frame(main_frame, bg='white', relief=tk.RAISED, bd=2)
        self.right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True, padx=(5, 0))

        # Left side - Reference Video
        tk.Label(self.left_frame, text="Reference Video", font=("Arial", 16, "bold"), bg='white').pack(pady=5)

        video_frame = tk.Frame(self.left_frame, bg='white')
        video_frame.pack(fill=tk.BOTH, expand=True, pady=5)

        # Canvasè‡ªé€‚åº”
        self.canvas_file = tk.Canvas(video_frame, bg="black")
        self.canvas_file.pack(fill=tk.BOTH, expand=True, pady=5)
        self.canvas_file.create_text(350, 262, text="No video loaded", fill="white", font=("Arial", 12))

        self.controls_file = tk.Frame(self.left_frame, bg='white')
        self.controls_file.pack(side=tk.BOTTOM, pady=10)
        tk.Button(self.controls_file, text="ğŸ“ Open Video", command=self.load_video,
                  bg='lightblue', font=("Arial", 10), width=12).pack(side=tk.LEFT, padx=2)
        tk.Button(self.controls_file, text="â–¶ï¸ Start Video", command=self.start_video,
                  bg='lightgreen', font=("Arial", 10), width=12).pack(side=tk.LEFT, padx=2)
        tk.Button(self.controls_file, text="â¹ï¸ Stop Video", command=self.stop_video,
                  bg='lightcoral', font=("Arial", 10), width=12).pack(side=tk.LEFT, padx=2)
        tk.Button(self.controls_file, text="ğŸ”„ Show/Hide", command=self.toggle_video_display,
                  bg='lightyellow', font=("Arial", 10), width=12).pack(side=tk.LEFT, padx=2)

        # Right side - Webcam
        tk.Label(self.right_frame, text="Your Webcam", font=("Arial", 16, "bold"), bg='white').pack(pady=5)
        cam_frame = tk.Frame(self.right_frame, bg='white')
        cam_frame.pack(fill=tk.BOTH, expand=True, pady=5)
        self.canvas_cam = tk.Canvas(cam_frame, bg="black")
        self.canvas_cam.pack(fill=tk.BOTH, expand=True, pady=5)
        self.canvas_cam.create_text(350, 262, text="Webcam not started", fill="white", font=("Arial", 12))

        self.controls_cam = tk.Frame(self.right_frame, bg='white')
        self.controls_cam.pack(side=tk.BOTTOM, pady=10)
        tk.Button(self.controls_cam, text="ğŸ“· Start Webcam", command=self.start_cam,
                  bg='lightgreen', font=("Arial", 10), width=15).pack(side=tk.LEFT, padx=5)
        tk.Button(self.controls_cam, text="â¹ï¸ Stop Webcam", command=self.stop_cam,
                  bg='lightcoral', font=("Arial", 10), width=15).pack(side=tk.LEFT, padx=5)

        # Bottom info frame
        self.info_frame = tk.Frame(self.root, bg='lightgray')
        self.info_frame.pack(side=tk.BOTTOM, fill=tk.X, pady=5)
        self.info_label = tk.Label(self.info_frame,
                                   text="âœ… Ready to start! Click 'Start Webcam' to test pose detection.",
                                   font=("Arial", 12), bg='lightgray', fg='darkgreen')
        self.info_label.pack()
        self.status_frame = tk.Frame(self.info_frame, bg='lightgray')
        self.status_frame.pack(pady=5)
        self.video_status = tk.Label(self.status_frame, text="ğŸ“¹ Video: Stopped",
                                     font=("Arial", 10), bg='lightgray')
        self.video_status.pack(side=tk.LEFT, padx=10)
        self.cam_status = tk.Label(self.status_frame, text="ğŸ“· Webcam: Stopped",
                                   font=("Arial", 10), bg='lightgray')
        self.cam_status.pack(side=tk.LEFT, padx=10)
        # åˆ†æ•°åŒºè‡ªé€‚åº”
        self.score_frame = tk.Frame(self.root, bg='white', relief=tk.RAISED, bd=2)
        self.score_frame.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)
        tk.Label(self.score_frame, text="åˆ†æ•°ç»Ÿè®¡", font=("Arial", 14, "bold"), bg='white').pack(pady=5)
        self.pose_score_var = tk.StringVar(value="å§¿æ€åˆ†: 0.00")
        self.rhythm_score_var = tk.StringVar(value="èŠ‚å¥åˆ†: 0.00")
        self.total_score_var = tk.StringVar(value="æ€»åˆ†: 0.00")
        self.avg_score_var = tk.StringVar(value="ç´¯è®¡å¹³å‡åˆ†: 0.00")
        self.similarity_var = tk.StringVar(value="ç›¸ä¼¼åº¦: 0.00")
        tk.Label(self.score_frame, textvariable=self.similarity_var, font=("Arial", 12), bg='white').pack()
        tk.Label(self.score_frame, textvariable=self.pose_score_var, font=("Arial", 12), bg='white').pack()
        tk.Label(self.score_frame, textvariable=self.rhythm_score_var, font=("Arial", 12), bg='white').pack()
        tk.Label(self.score_frame, textvariable=self.total_score_var, font=("Arial", 12), bg='white').pack()
        tk.Label(self.score_frame, textvariable=self.avg_score_var, font=("Arial", 12), bg='white').pack()
        self.fig, self.ax = plt.subplots(figsize=(4,1.2), dpi=100)
        self.score_canvas = FigureCanvasTkAgg(self.fig, master=self.score_frame)
        self.score_canvas.get_tk_widget().pack(pady=5, fill=tk.BOTH, expand=True)

    def load_video(self):
        path = filedialog.askopenfilename(
            title="Select Dance Video",
            filetypes=[("Video files", "*.mp4 *.avi *.mov *.mkv"), ("All files", "*.*")]
        )
        if path:
            self.video_path = path
            filename = os.path.basename(path)
            self.info_label.config(text=f"âœ… Video loaded: {filename}")
            # åœ¨Canvasä¸Šæ˜¾ç¤ºæ–‡æœ¬
            self.canvas_file.delete("all")
            self.canvas_file.create_text(350, 262, text=f"Video loaded:\n{filename}",
                                         fill="white", font=("Arial", 12))
            # æ–°å¢ï¼šè‡ªåŠ¨æå–èŠ‚æ‹é”šç‚¹
            try:
                audio_path = mp4_2_mp3(path)
                tempo, beats, beat_times = get_beats(audio_path)
                self.beat_times = beat_times.tolist() if hasattr(beat_times, 'tolist') else list(beat_times)
                self.info_label.config(text=f"ğŸµ èŠ‚æ‹é”šç‚¹æå–å®Œæˆï¼Œå…±{len(self.beat_times)}ä¸ª")
            except Exception as e:
                self.beat_times = []
                self.info_label.config(text=f"âš ï¸ èŠ‚æ‹æå–å¤±è´¥: {e}")

    def start_video(self):
        if not self.video_path:
            messagebox.showwarning("No Video", "Please select a video file first!")
            return
        if not self.running_file:
            self.running_file = True
            self.video_status.config(text="ğŸ“¹ Video: Playing", fg='green')
            self.info_label.config(text="ğŸ¬ Video playing! You can now compare with webcam.")
            threading.Thread(target=self.process_video_file, daemon=True).start()

    def stop_video(self):
        self.running_file = False
        self.video_status.config(text="ğŸ“¹ Video: Stopped", fg='red')
        self.info_label.config(text="â¹ï¸ Video stopped.")
        # åœ¨Canvasä¸Šæ˜¾ç¤ºåœæ­¢æ–‡æœ¬
        self.canvas_file.delete("all")
        self.canvas_file.create_text(350, 262, text="Video stopped", fill="white", font=("Arial", 12))
        if self.cap_file:
            self.cap_file.release()

    def toggle_video_display(self):
        self.show_video_frame = not self.show_video_frame
        mode = "Original video" if self.show_video_frame else "Pose skeleton only"
        self.info_label.config(text=f"ğŸ”„ Display mode: {mode}")

    def start_cam(self):
        if not self.running_cam:
            self.running_cam = True
            self.cam_status.config(text="ğŸ“· Webcam: Running", fg='green')
            self.info_label.config(text="ğŸ“· Webcam started! Move around to test pose detection.")
            threading.Thread(target=self.process_webcam, daemon=True).start()

    def stop_cam(self):
        self.running_cam = False
        self.cam_status.config(text="ğŸ“· Webcam: Stopped", fg='red')
        self.info_label.config(text="ğŸ“· Webcam stopped.")
        # åœ¨Canvasä¸Šæ˜¾ç¤ºåœæ­¢æ–‡æœ¬
        self.canvas_cam.delete("all")
        self.canvas_cam.create_text(350, 262, text="Webcam stopped", fill="white", font=("Arial", 12))
        if self.cap_cam:
            self.cap_cam.release()

    def process_video_file(self):
        try:
            self.cap_file = cv2.VideoCapture(self.video_path)
            if not self.cap_file.isOpened():
                messagebox.showerror("Error", "Cannot open video file!")
                return

            fps = self.cap_file.get(cv2.CAP_PROP_FPS) or 30
            delay = max(1, int(1000 / fps))

            while self.cap_file.isOpened() and self.running_file:
                ret, frame = self.cap_file.read()
                if not ret:
                    # Video ended, restart from beginning
                    self.cap_file.set(cv2.CAP_PROP_POS_FRAMES, 0)
                    continue

                processed_frame = self.process_pose(frame, which='file')
                self.update_canvas(self.canvas_file, processed_frame)

                cv2.waitKey(delay)

        except Exception as e:
            messagebox.showerror("Video Error", f"Error processing video: {str(e)}")
        finally:
            if self.cap_file:
                self.cap_file.release()

    def process_webcam(self):
        try:
            self.cap_cam = cv2.VideoCapture(0)
            if not self.cap_cam.isOpened():
                messagebox.showerror("Error", "Cannot open webcam!")
                return

            while self.cap_cam.isOpened() and self.running_cam:
                ret, frame = self.cap_cam.read()
                if not ret:
                    continue

                # Flip frame horizontally for mirror effect
                frame = cv2.flip(frame, 1)
                processed_frame = self.process_pose(frame, which='cam')
                self.update_canvas(self.canvas_cam, processed_frame)

        except Exception as e:
            messagebox.showerror("Webcam Error", f"Error processing webcam: {str(e)}")
        finally:
            if self.cap_cam:
                self.cap_cam.release()

    def process_pose(self, frame, which='file'):
        """é›†æˆè‡ªå®šä¹‰æ£€æµ‹å™¨/æ»¤æ³¢/è¡¥å…¨/è¿½è¸ªï¼Œæ”¯æŒå¤šäººã€æ‰‹åŠ¿ã€ä¼˜åŒ–å‰åå¯¹æ¯”"""
        import copy
        height, width = frame.shape[:2]
        # é€‰æ‹©å¯¹åº”å¯¹è±¡
        if which == 'file':
            pose_manager = self.file_pose_manager
            tracker = self.file_tracker
        else:
            pose_manager = self.cam_pose_manager
            tracker = self.cam_tracker
        # æ£€æµ‹
        persons, det_info = pose_manager.detect_poses(frame)
        # è®°å½•åŸå§‹å…³é”®ç‚¹
        orig_persons = copy.deepcopy(persons)
        # é®æŒ¡è¡¥å…¨
        if self.fixer_method and persons:
            keypoints_seq = [[np.array([kp.x, kp.y]) for kp in p.keypoints] for p in persons]
            conf_seq = [[np.array([kp.confidence for kp in p.keypoints])] for p in persons]
            if keypoints_seq and all(len(kps) >= 1 for kps in keypoints_seq):
                fixed_kps = fix_keypoints([keypoints_seq], [conf_seq], method=self.fixer_method)[0]
                for i, p in enumerate(persons):
                    for j, kp in enumerate(p.keypoints):
                        kp.x, kp.y = fixed_kps[i][j][0], fixed_kps[i][j][1]
        # å¹³æ»‘æ»¤æ³¢
        if self.smoother_method and persons:
            keypoints_seq = [[np.array([kp.x, kp.y]) for kp in p.keypoints] for p in persons]
            if keypoints_seq and all(len(kps) >= 1 for kps in keypoints_seq):
                smoothed_kps = smooth_keypoints([keypoints_seq], method=self.smoother_method)[0]
                for i, p in enumerate(persons):
                    for j, kp in enumerate(p.keypoints):
                        kp.x, kp.y = smoothed_kps[i][j][0], smoothed_kps[i][j][1]
        # å¤šäººè¿½è¸ª
        if self.tracker_enable and persons and tracker is not None:
            dets = [{'keypoints': np.array([[kp.x, kp.y] for kp in p.keypoints]), 'bbox': np.array(p.bbox)} for p in persons]
            tracked = tracker.update(dets, 0)
            for i, p in enumerate(persons):
                p.id = tracked[i]['id'] if i < len(tracked) else p.id
        # å¯è§†åŒ–
        if self.show_video_frame:
            output_frame = frame.copy()
        else:
            output_frame = np.ones_like(frame) * 255
        output_frame = draw_persons(output_frame, persons, self.detector_type)
        fps = 1000.0 / max(det_info.get('processing_time_ms', 1), 1)
        cv2.putText(output_frame, f"Detector: {self.detector_type.value} | Smoother: {self.smoother_method or 'None'} | Fixer: {self.fixer_method or 'None'} | Tracker: {self.tracker_enable}",
                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 128, 255), 2)
        cv2.putText(output_frame, f"FPS: {fps:.1f} | Persons: {len(persons)}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 128, 255), 2)
        # è®°å½•ä¸»èˆè€…landmarks
        # å¥å£®æ€§åˆ¤æ–­ï¼Œç¡®ä¿æœ‰ä¸»èˆè€…ä¸”å…³é”®ç‚¹æ•°é‡è¶³å¤Ÿ
        if persons and hasattr(persons[0], 'keypoints') and persons[0].keypoints:
            kps = persons[0].keypoints
            if len(kps) < 33:
                class DummyKP:
                    x, y, z = 0.0, 0.0, 0.0
                kps = list(kps) + [DummyKP() for _ in range(33 - len(kps))]
            class LM:
                pass
            lm = LM()
            class L:
                pass
            lm.landmark = [L() for _ in range(33)]
            for i in range(33):
                kp = kps[i]
                lm.landmark[i].x = getattr(kp, 'x', 0.0)
                lm.landmark[i].y = getattr(kp, 'y', 0.0)
                lm.landmark[i].z = getattr(kp, 'z', 0.0)
            if which == 'file':
                self.last_file_landmarks = lm
            else:
                self.last_cam_landmarks = lm
        else:
            if which == 'file':
                self.last_file_landmarks = None
            else:
                self.last_cam_landmarks = None
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = None
        if self.last_file_landmarks and self.last_cam_landmarks:
            similarity = calc_similarity(self.last_file_landmarks, self.last_cam_landmarks)
            self.last_similarity = similarity
        if self.last_similarity is not None:
            cv2.putText(output_frame, f"Similarity: {self.last_similarity:.2f}", (10, 90),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2)
        pose_score = rhythm_score = total_score = avg_score = 0.0
        delta_t = 1.0  # å…ˆç»™é»˜è®¤å€¼ï¼Œé˜²æ­¢æœªå®šä¹‰
        if self.last_file_landmarks and self.last_cam_landmarks:
            pose_score = calc_similarity(self.last_file_landmarks, self.last_cam_landmarks)
            rhythm_score = 0.0
            if self.beat_times and which == 'cam':
                frame_idx = len(self.score_history)
                current_time = frame_idx / 30.0
                try:
                    delta_t = min([abs(current_time - t) for t in self.beat_times])
                except:
                    delta_t = 1.0
                rhythm_score = max(0, 1 - delta_t / 0.4)
            total_score = score_pose(pose_score, delta_t if self.beat_times else 1.0)
            self.cumulative_score.update(total_score)
            avg_score = self.cumulative_score.average
            self.score_history.append(total_score)
        self.similarity_var.set(f"ç›¸ä¼¼åº¦: {self.last_similarity:.2f}" if self.last_similarity is not None else "ç›¸ä¼¼åº¦: 0.00")
        self.pose_score_var.set(f"å§¿æ€åˆ†: {pose_score:.2f}")
        self.rhythm_score_var.set(f"èŠ‚å¥åˆ†: {rhythm_score:.2f}")
        self.total_score_var.set(f"æ€»åˆ†: {total_score:.2f}")
        self.avg_score_var.set(f"ç´¯è®¡å¹³å‡åˆ†: {avg_score:.2f}")
        self.update_score_plot()
        return output_frame

    def update_canvas(self, canvas, frame):
        try:
            canvas.update_idletasks()
            w = canvas.winfo_width()
            h = canvas.winfo_height()
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = Image.fromarray(rgb)
            img = img.resize((w, h))
            imgtk = ImageTk.PhotoImage(image=img)
            canvas.delete("all")
            canvas.create_image(w//2, h//2, image=imgtk)
            canvas.imgtk = imgtk
        except Exception as e:
            print(f"Error updating canvas: {e}")

    def update_score_plot(self):
        self.ax.clear()
        self.ax.plot(self.score_history, color='orange', label='æ€»åˆ†')
        self.ax.set_ylim(0, 1.05)
        self.ax.set_ylabel('åˆ†æ•°')
        self.ax.set_xlabel('å¸§')
        self.ax.legend(loc='upper right')
        self.ax.grid(True, linestyle='--', alpha=0.3)
        self.fig.tight_layout()
        self.score_canvas.draw()

    def cleanup(self):
        """Cleanup resources"""
        self.running_file = False
        self.running_cam = False
        if self.cap_file:
            self.cap_file.release()
        if self.cap_cam:
            self.cap_cam.release()
        if hasattr(self, 'pose'):
            self.pose.close()


# ç”¨äºå§¿æ€ç›¸ä¼¼åº¦è®¡ç®—çš„å·¥å…·ç±»
class SimilarityCalculator:
    def __init__(self):
        pass

    def calculate(self, lm1, lm2):
        return calculate_pose_similarity(lm1, lm2)

    def center_landmarks(self, landmarks):
        return center_landmarks(landmarks)

    def normalize_landmarks(self, landmarks_np):
        return normalize_landmarks(landmarks_np)


def main():
    # å¯é€šè¿‡å‘½ä»¤è¡Œæˆ–é…ç½®æ–‡ä»¶åˆ‡æ¢å‚æ•°ï¼Œè¿™é‡Œç”¨é»˜è®¤å‚æ•°
    root = tk.Tk()
    app = MediaPipePoseApp(root,
                          detector_type=DetectorType.MEDIAPIPE,  # å¯é€‰: MEDIAPIPE/YOLOV8/HYBRID
                          smoother_method=None,                   # å¯é€‰: 'ema'/'kalman'/None
                          fixer_method=None,                      # å¯é€‰: 'linear'/'symmetric'/None
                          tracker_enable=True)                   # True/False
    def on_closing():
        app.cleanup()
        root.destroy()
    root.protocol("WM_DELETE_WINDOW", on_closing)
    print("ğŸš€ Starting MediaPipe Dance GUI... (with custom pipeline)")
    root.mainloop()


if __name__ == "__main__":
    main()